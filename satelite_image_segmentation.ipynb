{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "from patchify import patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Semantic_segmentation_dataset/'\n",
    "scaler = MinMaxScaler()\n",
    "patch_size = 256\n",
    "images = []\n",
    "masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patch_images(data_dir):\n",
    "    image_dataset = []\n",
    "    for path, subdirs, files in os.walk(data_dir):\n",
    "\n",
    "        directory_name = path.split(os.path.sep)[-1]\n",
    "        if directory_name == 'images':\n",
    "            images = os.listdir(path)\n",
    "            for i, image_name in enumerate(images):  \n",
    "                if image_name.endswith(\".jpg\"):\n",
    "                \n",
    "                    image = cv2.imread(path+\"/\"+image_name, 1)\n",
    "                    X_shape = (image.shape[1]//patch_size)*patch_size\n",
    "                    Y_shape = (image.shape[0]//patch_size)*patch_size\n",
    "\n",
    "                    image = Image.fromarray(image)\n",
    "                    image = image.crop((0 ,0, X_shape, Y_shape))\n",
    "                    image = np.array(image)\n",
    "\n",
    "                    patch_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "                    for i in range(patch_img.shape[0]):\n",
    "                        for j in range(patch_img.shape[1]):\n",
    "                            single_patch_img = patch_img[i,j,:,:]\n",
    "                            single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)                        \n",
    "                            single_patch_img = single_patch_img[0]\n",
    "                            image_dataset.append(single_patch_img)\n",
    "\n",
    "    return np.array(image_dataset), single_patch_img\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patch_masks(data_dir):\n",
    "    image_dataset = []\n",
    "    for path, subdirs, files in os.walk(data_dir):\n",
    "\n",
    "        directory_name = path.split(os.path.sep)[-1]\n",
    "        if directory_name == 'masks':\n",
    "            images = os.listdir(path)\n",
    "            for i, image_name in enumerate(images):  \n",
    "                if image_name.endswith(\".png\"):\n",
    "                \n",
    "                    image = cv2.imread(path+\"/\"+image_name, 1)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    X_shape = (image.shape[1]//patch_size)*patch_size\n",
    "                    Y_shape = (image.shape[0]//patch_size)*patch_size\n",
    "\n",
    "                    image = Image.fromarray(image)\n",
    "                    image = image.crop((0 ,0, X_shape, Y_shape))\n",
    "                    image = np.array(image)\n",
    "\n",
    "                    patch_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "                    for i in range(patch_img.shape[0]):\n",
    "                        for j in range(patch_img.shape[1]):\n",
    "                            single_patch_img = patch_img[i,j,:,:]\n",
    "                            single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)                        \n",
    "                            single_patch_img = single_patch_img[0]\n",
    "                            image_dataset.append(single_patch_img)\n",
    "\n",
    "    return np.array(image_dataset) , single_patch_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images , single_patch_img = np.array(load_patch_images(data_dir))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks , single_patch_mask = np.array(load_patch_masks(data_dir))\n",
    "masks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([155, 155, 155])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Building = '#3C1098'.lstrip('#')\n",
    "Land = '#8429F6'.lstrip('#')\n",
    "Road = '#6EC1E4'.lstrip('#') \n",
    "Vegetation =  'FEDD3A'.lstrip('#') \n",
    "Water = 'E2A929'.lstrip('#') \n",
    "Unlabeled = '#9B9B9B'.lstrip('#') \n",
    "\n",
    "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
    "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
    "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
    "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
    "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
    "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = pd.read_csv(\"class_dict.csv\", index_col=False, skipinitialspace=True)\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([132,  41, 246], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names= list(class_dict.name)\n",
    "label_codes = []\n",
    "r= np.asarray(class_dict['r'])\n",
    "g= np.asarray(class_dict['g'])\n",
    "b= np.asarray(class_dict['b'])\n",
    "\n",
    "h = np.array(tuple([r[1], g[1], b[1]]))\n",
    "\"\"\"\n",
    "for i in range(len(class_dict)):\n",
    "    label_codes.append(tuple([r[i], g[i], b[i]]))\n",
    "\n",
    "\n",
    "    \n",
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(label_names)}\n",
    "id2name = {k:v for k,v in enumerate(label_names)}\n",
    "\"\"\"\n",
    "\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "042f1467ab0111aa983a1a2722ed4e9691068ebac51e10c18c39c936081e164b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
